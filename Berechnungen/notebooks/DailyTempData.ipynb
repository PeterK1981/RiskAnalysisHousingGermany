{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7a9f9d-f047-4a8c-879e-4304ca2e4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import choropleth_pipeline as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm, TwoSlopeNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f96206-17a7-49b0-ada4-5d968db9a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_col = \"D30\"\n",
    "\n",
    "for year in range(2000,2025):\n",
    "    vals = pd.read_parquet(f\"cache/hitze_metrics_gem_year_{year}.parquet\")\n",
    "    \n",
    "    vg  = cp.VG250Spec(gpkg_path=r\"..\\geometry\\DE_VG250.gpkg\", id_col=\"ARS\")\n",
    "    gem = cp.load_level(vg, \"GEM\")[[\"ARS\",\"geometry\"]].copy()\n",
    "    laender = cp.load_level(vg, 'LAN').copy()\n",
    "    gem[\"ARS\"] = gem[\"ARS\"].astype(\"string\")\n",
    "    \n",
    "    \n",
    "    gdf = gem.merge(vals, on = 'ARS', how = 'inner')\n",
    "    \n",
    "    fig, ax = cp.plot_choropleth_continuous(\n",
    "        gdf,\n",
    "        value_col=value_col,\n",
    "        cmap_name=\"OrRd\",          \n",
    "        title=f\"{value_col} {year}\",\n",
    "        laender = laender,\n",
    "        figsize=(8, 10),\n",
    "        norm = TwoSlopeNorm(vmin=0, vcenter=5, vmax=10)\n",
    "    )\n",
    "    out_file = cp.save_map(\n",
    "        fig, \n",
    "        filename=f\"{value_col}_{year}.png\", \n",
    "        out_dir=\"exports/Hitze\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4114bb-5973-44ec-882d-a7e82147b089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'ARS', 'H30', 'H32', 'H35', 'I30', 'H30_any', 'H32_any',\n",
       "       'H35_any', 'H30_frac10', 'H32_frac10', 'H35_frac10', 'D30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9485e4f-3e8d-435c-9da9-5359cae3140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Robust-Standardisierung ----------\n",
    "def robust_z(s: pd.Series, clip=3.0) -> pd.Series:\n",
    "    s = s.astype(float)\n",
    "    med = np.nanmedian(s)\n",
    "    mad = np.nanmedian(np.abs(s - med))\n",
    "    scale = 1.4826 * mad\n",
    "    if not np.isfinite(scale) or scale == 0:  # Fallbacks\n",
    "        q75, q25 = np.nanpercentile(s, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        scale = iqr / 1.349 if iqr > 0 else np.nanstd(s)\n",
    "    if not np.isfinite(scale) or scale == 0:\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)  # alles gleich\n",
    "    z = (s - med) / scale\n",
    "    return z.clip(-clip, clip)\n",
    "\n",
    "# ---------- Loader ----------\n",
    "def load_years(cache_dir: str | Path, start_year: int, end_year: int) -> pd.DataFrame:\n",
    "    cache_dir = Path(cache_dir)\n",
    "    dfs = []\n",
    "    for y in range(start_year, end_year + 1):\n",
    "        f = cache_dir / f\"hitze_metrics_gem_year_{y}.parquet\"\n",
    "        if f.exists():\n",
    "            df = pd.read_parquet(f, columns=[\"year\",\"ARS\",\"H30\",\"H32\",\"H35\",\"I30\"])\n",
    "            dfs.append(df)\n",
    "    if not dfs:\n",
    "        raise FileNotFoundError(\"Keine Jahres-Parquets im Zeitraum gefunden.\")\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "    out[\"ARS\"] = out[\"ARS\"].astype(str)  # ARS unverändert als String\n",
    "    return out\n",
    "\n",
    "# ---------- Hauptfunktion ----------\n",
    "def compute_heat_index(cache_dir=\"cache\",\n",
    "                       start_year=2020, end_year=2024,\n",
    "                       min_years=3, variant=\"A\",\n",
    "                       scale_to_0_100=True):\n",
    "    df = load_years(cache_dir, start_year, end_year)\n",
    "\n",
    "    # Zeitraummittel je Gemeinde\n",
    "    agg = (df.groupby(\"ARS\")\n",
    "             .agg(years_used=(\"year\",\"nunique\"),\n",
    "                  H30_mean=(\"H30\",\"mean\"),\n",
    "                  H32_mean=(\"H32\",\"mean\"),\n",
    "                  H35_mean=(\"H35\",\"mean\"),\n",
    "                  I30_mean=(\"I30\",\"mean\"))\n",
    "             .reset_index())\n",
    "    agg = agg[agg[\"years_used\"] >= min_years].copy()\n",
    "\n",
    "    # robuste z-Scores (über Gemeinden)\n",
    "    for col in [\"H30_mean\",\"H32_mean\",\"H35_mean\",\"I30_mean\"]:\n",
    "        agg[col + \"_z\"] = robust_z(agg[col])\n",
    "\n",
    "    # Index-Formel\n",
    "    if variant.upper() == \"A\":  # schlank (empfohlen)\n",
    "        agg[\"Index_raw\"] = 0.6*agg[\"I30_mean_z\"] + 0.4*agg[\"H35_mean_z\"]\n",
    "    else:  # \"B\": ausgewogen\n",
    "        agg[\"z_freq\"]   = (agg[\"H30_mean_z\"] + agg[\"H32_mean_z\"]) / 2.0\n",
    "        agg[\"Index_raw\"] = 0.4*agg[\"z_freq\"] + 0.4*agg[\"I30_mean_z\"] + 0.2*agg[\"H35_mean_z\"]\n",
    "\n",
    "    # robuster 0–100 Score\n",
    "    if scale_to_0_100:\n",
    "        p1, p99 = np.nanpercentile(agg[\"Index_raw\"], [1, 99])\n",
    "        denom = (p99 - p1) if p99 > p1 else (agg[\"Index_raw\"].max() - agg[\"Index_raw\"].min() or 1.0)\n",
    "        agg[\"Index_0_100\"] = ((agg[\"Index_raw\"] - p1) / denom * 100).clip(0, 100)\n",
    "\n",
    "    cols = [\"ARS\",\"years_used\",\"H30_mean\",\"H32_mean\",\"H35_mean\",\"I30_mean\",\n",
    "            \"H30_mean_z\",\"H32_mean_z\",\"H35_mean_z\",\"I30_mean_z\",\"Index_raw\"]\n",
    "    if \"Index_0_100\" in agg:\n",
    "        cols.append(\"Index_0_100\")\n",
    "    return agg[cols].sort_values(\"Index_raw\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---------- Beispielaufrufe ----------\n",
    "# 5-Jahres-Fenster 2020–2024, Variante A:\n",
    "idx_2020_24 = compute_heat_index(\"cache\", 2020, 2024, min_years=3, variant=\"A\")\n",
    "# Längeres Fenster 2000–2024, Variante B:\n",
    "idx_2000_24 = compute_heat_index(\"cache\", 2000, 2024, min_years=10, variant=\"B\")\n",
    "\n",
    "# Optional speichern:\n",
    "# idx_2020_24.to_parquet(\"out/hitze_index_2020_2024.parquet\", index=False)\n",
    "# idx_2000_24.to_parquet(\"out/hitze_index_2000_2024.parquet\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
